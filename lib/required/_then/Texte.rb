# encoding: UTF-8
require 'fileutils'

class Texte
include ConfigModule
# ---------------------------------------------------------------------
#
#   INSTANCE
#
# ---------------------------------------------------------------------
attr_reader :path, :lemmatized_file_path
attr_reader :items
# Le premier mot (ou non mot) courant
attr_accessor :current_first_item

def initialize(path)
  @path = path
  # db.create_base_if_necessary
  # db.execute("UPDATE configuration SET value = #{Time.now.to_i} WHERE name = 'LastOpening'")
  # db.db.close if db.db
rescue Exception => e
  erreur(e)
end #/ initialize

def reset(key)
  instance_variable_set("@#{key}", nil)
end #/ reset

# def db
#   @db ||= TextSQLite.new(self)
# end #/ db

# Reconstruction totale du texte.
def rebuild
  CWindow.log("Je dois reconstruire le texte.")
end #/ rebuild

# Essai de recomptage de tout pour voir le temps que √ßa prend
def recompte(params = nil)
  params ||= {}
  start_time = Time.now.to_f
  offset = 0
  nb = 0
  # Les canons qu'il faudra actualiser
  canons_to_update = {}
  params.merge!(from: 0) unless params.key?(:from)
  idx = params[:from] - 1
  while titem = self.items[idx += 1]
    # Si le d√©calage du mot change et que son canon n'est pas encore √†
    # actualiser, il faut l'enregistrer pour l'actualiser
    if titem.mot? && titem.offset != offset && !canons_to_update.key?(titem.canon)
      raise "Le canon de #{titem.inspect} n'est pas d√©fini" if titem.canon.nil? || titem.icanon.nil?
      canons_to_update.merge!(titem.canon => titem.icanon)
    end
    titem.offset = offset
    titem.index  = idx
    offset += titem.length + 1 # approximatif car on n'ajoute pas toujours 1 espace
    nb += 1
  end

  # Actualisation des canons
  # ------------------------
  erreurs = []
  canons_to_update.each do |canon, icanon|
    if icanon.nil?
      erreurs << "ERREUR CANON: Le canon #{canon.inspect} est nul"
    else
      icanon.update
    end
  end
  unless erreurs.empty?
    CWindow.error("Une erreur est survenue avec les canons. Quitter et consulter le journal.")
    log("### ERREUR UPDATE CANON ####{RC}#{erreurs.join(RC)}")
  end

  end_time = Time.now.to_f
  CWindow.log("Fin du recalcul. Quitter et pour voir le temps.")

  log("Dur√©e du recomptage de #{nb} items : #{end_time - start_time}")
end #/ recompte

# On doit forcer la r√©-analyse du texte
def reproximitize
  CWindow.logWind.write('R√©-analyse du texte‚Ä¶')
  File.delete(data_path) if File.exists?(data_path)
  parse || return
  CWindow.logWind.write('Texte analys√© avec succ√®s.')
  return true
end #/ reproximitize

def save
  data = {
    items: items,
    canons:  Canon.items_as_hash,
    path:  path,
    updated_at: Time.now,
    created_at: Time.now
  }
  File.open(data_path,'wb'){|f| Marshal.dump(data,f)}
end #/ save

def load
  @data = Marshal.load(File.read(data_path))
  @items = @data[:items]
  @current_first_item = config[:last_first_index]
  Canon.items_as_hash = @data[:canons]
end #/ load

# Il faut voir s'il est n√©cessaire de parser le fichier. C'est n√©cessaire
# si le fichier d'analyse n'existe pas ou s'il est plus vieux que le
# nouveau texte.
def parse_if_necessary
  if out_of_date?
    # log "Le fichier doit √™tre actualis√©"
    parse || return
    log("üëç¬†PARSING OP√âR√â AVEC SUCC√àS".freeze)
  else
    # log "Le fichier est √† jour"
    load
  end
  return true
end #/ parse_if_necessary


# Retourne TRUE s'il faut proc√©der √† l'analyse √† nouveau
def out_of_date?
  return true unless File.exists?(data_path)
  return File.stat(data_path).mtime < File.stat(path).mtime
end #/ out_of_date?

def init
  @items = []
  self.current_first_item = 0
end #/ init

# = main =
#
# M√©thode principale qui traite le fichier
#
# Traiter le fichier consiste √† en faire une entit√© proximit√©, c'est-√†-dire
# un d√©coupage du texte en paragraphes, lines, mots, locutions, non-mots,
# pour permettre le traitement par l'application.
# Le traitement se fait par stream donc le fichier peut avoir une taille
# cons√©quente sans probl√®me
def parse

  # Pour savoir le temps que √ßa prend
  start = Time.now.to_f
  log("Parsing du texte #{path}")

  # Initialisations
  self.init
  Canon.init

  # Pr√©paration du texte
  # --------------------
  # Pour un projet Scrivener, √ßa consiste √† reconstituer tout le
  # texte si n√©cessaire.
  # La pr√©paration consiste √†
  #   effectuer quelques corrections comme les apostrophes courbes.
  # Le texte corrig√© est mis dans un fichier portant le m√™me nom que le
  # fichier original mais la marque 'c' est il sera normalement d√©truit √†
  # la fin du processus.
  prepare || return

  # On lemmatise la liste de tous les mots, on ajoutant chaque
  # mot √† son canon.
  lemmatize || return

  # On doit recalculer tout le texte. C'est-√†-dire d√©finir les
  # offsets de tous les √©l√©ments
  recompte || return

  # On termine en enregistrant la donn√©e finale
  save

  delai = Time.now.to_f - start
  puts "D√©lai secondes m√©thode : #{delai}"

  return true
rescue Exception => e
  log("PROBL√àME EN PARSANT le texte #{path} : #{e.message}#{RC}#{e.backtrace.join(RC)}")
  CWindow.error("Une erreur est survenue : #{e.message} (quitter et consulter le journal)")
ensure
  File.delete(corrected_text_path) if File.exists?(corrected_text_path)
end

# Pour "Re-pr√©parer" le texte, c'est-√†-dire refaire tout le travail
# de d√©coupage du texte en mots et non-mots, son calcul des proximit√©s
# et l'affichage de son extrait.
# ATTENTION : Cette proc√©dure d√©truit toutes les transformations d√©j√†
# op√©r√©es
def reprepare
  [data_path, main_file_txt, only_mots_path].each do |fpath|
    File.delete(fpath) if File.exists?(fpath)
  end
  parse
end #/ reprepare

def prepare

  # Pr√©paration d'un fichier "full-texte" contenant tout le texte √† corriger
  if projet_scrivener?
    prepare_as_projet_scrivener || return
  else # simple copie si pas projet Scrivener
    FileUtils.copy(path, main_file_txt)
  end

  # Pr√©paration d'un fichier corrig√©, √† partir du fichier full-texte
  prepare_fichier_corriged || return

  # D√©coupage du fichier corrig√© en mots et non-mots
  decoupe_fichier_corriged || return

  return true
end #/ prepare

# Tous les signes, dans le texte, qui vont √™tre consid√©r√©s comme ne
# constituant pas un mot. Donc les apostrophes et les tirets sont exclus.
DELIMITERS = ' ¬†?!,;:\.‚Ä¶‚Äî‚Äì=+$¬•‚Ç¨¬´¬ª' # pas de trait d'union, pas d'apostrophe

MOT_NONMOT_REG = /([#{DELIMITERS}]+)?([^#{DELIMITERS}]+)([#{DELIMITERS}]+)/

# On d√©coupe le fichier corrig√© en mot et non mots
def decoupe_fichier_corriged
  # On pr√©pare le fichier pour la l√©mmatisation. Il ne contiendra que
  # les mots, s√©par√©s par des espaces simple
  File.delete(only_mots_path) if File.exists?(only_mots_path)
  refonlymots = File.open(only_mots_path,'a')
  # On le fait par paragraphe pour ne pas avoir trop √† traiter d'un coup
  File.foreach(corrected_text_path) do |line|
    # log("Phrase originale: #{line.inspect}")
    new_items = traite_line_of_texte(line.strip, refonlymots)
    log("#{new_items.count} ajout√©s √† itexte.items")
    @items += new_items
    # √Ä la fin de chaque ‚Äúligne‚Äù, il faut mettre une fin de paragraphe
    @items << NonMot.new(RC, type: 'paragraphe')
  end
  return true
rescue Exception => e
  erreur(e)
  return false
ensure
  refonlymots.close
end #/ decoupe_fichier_corriged

# +refmotscontainer+ R√©f√©rence au fichier contenant tous les mots,
# dans le mode normal et un fichier virtuel pour les insertions et
# remplacement.
def traite_line_of_texte(line, refmotscontainer)
  new_items = []
  line.scan(MOT_NONMOT_REG).to_a.each_with_index do |item, idx|
    # next if item.nil? # pas de premier d√©limiteur par exemple
    amorce, mot, nonmot = item # amorce : le tiret, par exemple, pour dialogue
    new_items << NonMot.new(amorce) unless amorce.nil?
    if mot.match?(/#{APO}/) && !MOTS_APOSTROPHE.key?(mot.downcase)
      # log("MOT APOSTROPHE √Ä D√âCOUPER : #{mot.inspect}")
      bouts = mot.split(APO)
      motav = bouts.shift
      motap = bouts.join(APO)
      motav += APO
      new_items << Mot.new(motav)
      new_items << Mot.new(motap)
    elsif mot.match?(/#{TIRET}/) && !MOTS_TIRETS.key?(mot.downcase)
      mots = []
      bouts = mot.split(TIRET)
      mots << bouts.shift
      motap = bouts.join(TIRET)
      if motap.match?(/#{TIRET}/) && !MOTS_TIRETS.key?(motap.downcase)
        mots += motap.split(TIRET)
        mots.last = "#{TIRET}#{mots.last}" # on garde "-il"
      else
        mots << "#{TIRET}#{motap}" # on garde "-il"
      end
      mots.each do |smot|
        new_items << Mot.new(smot)
      end
    else
      new_items << Mot.new(mot)
    end
    # Dans tous les cas, m√™me avec une apostrophe, on √©crit le mot tel
    # qu'il est. Parce que lors de la l√©mmatisation, avec l'apostrophe, il
    # y aura deux mots trouv√©s alors que "D' aussi" produira "D" (inconnu)
    # et "aussi"
    # On le met en minuscule, car sinon, la l√©mmatisation ne comprend pas
    # un mot avec capitale au milieu d'une phrase
    refmotscontainer.write("#{mot.downcase}#{SPACE}".freeze)
    new_items << NonMot.new(nonmot)
  end #/scan
  return new_items
end #/ traite_line_of_texte

# On prend le fichier total (contenant tout le texte initial) et on
# le corriger pour qu'il puisse √™tre trait√©
# Cette op√©ration @produit le fichier self.corrected_text_path
def prepare_fichier_corriged
  File.delete(corrected_text_path) if File.exists?(corrected_text_path)
  reffile = File.open(corrected_text_path,'a')
  begin
    File.foreach(main_file_txt) do |line|
      next if line == RC
      line = line.gsub(/‚Äô/, APO)
      reffile.puts line + PARAGRAPHE
    end
    return true
  rescue Exception => e
    erreur(e)
    return false
  ensure
    reffile.close
  end
end #/ prepare_fichier_corriged

# Quand on doit pr√©parer le texte comme un projet scrivener
def prepare_as_projet_scrivener
  log("-> prepare_as_projet_scrivener".freeze)
  ScrivFile.create_table_base_for(Runner.itexte) || return
  projet = Scrivener::Projet.new(path)
  # Pr√©parer le fichier contenant tout le texte si n√©cessaire
  unless File.exists?(main_file_txt)
    projet.produit_fichier_full_text || return
  end
  return true
rescue Exception => e
  erreur(e)
  return false
end #/ prepare_as_projet_scrivener

# L√©mmatiser le texte consiste √† le passer par tree-tagger ‚Äî ce qui prend
# quelques secondes m√™me pour un grand texte¬†‚Äî pour ensuite r√©cup√©rer chaque
# mot et connaitre son canon dans le texte final
def lemmatize
  @lemmatized_file_path = Lemma.parse(only_mots_path)
  # log("Contenu du fichier lemmatized_file_path : #{File.read(lemmatized_file_path)}")
  File.foreach(lemmatized_file_path).with_index do |line, mot_idx_in_lemma|
    next if line.strip.empty?
    traite_lemma_line(line, mot_idx_in_lemma) || break
  end # Fin de boucle sur chaque ligne du fichier de lemmatisation
  return true
end #/ lemmatize

# Traite une ligne de type mot TAB type TAB canon r√©cup√©rer
# des donn√©es de lemmatisation, soit au cours du parse complet du fichier
# √† travailler, soit aucun d'une insertion/remplacement
def traite_lemma_line(line, idx)
  mot, type, canon = line.strip.split(TAB)
  Mot.items[idx].type = type
  if mot != Mot.items[idx].content.downcase
    erreur("ERREUR FATALE LES MOTS NE CORRESPONDENT PLUS¬†:")
    imot = Mot.items[idx]
    log("mot:#{mot.inspect}, dans imot: #{imot.content.inspect}, type:#{type.inspect}, canon: #{canon.inspect}")
    return false
  else # quand tout est normal
    Canon.add(Mot.items[idx], canon)
  end
  return true
end #/ traite_lemma_line

def distance_minimale_commune
  @distance_minimale_commune ||= config[:distance_minimale_commune] || DISTANCE_MINIMALE_COMMUNE
end #/ distance_minimale_commune

# ---------------------------------------------------------------------
#
#  Question methods
#
# ---------------------------------------------------------------------
def projet_scrivener?
  extension == '.scriv' || extension == '.scrivx'
end #/ projet_scrivener?

# ---------------------------------------------------------------------
#
#   CHEMINS
#
# ---------------------------------------------------------------------

# Chemin d'acc√®s au fichier principal contenant tout le texte.
# C'est lui qui servira √† relever tous les mots et qui sera
# modifi√© √† la fin pour refl√©ter des changements.
def main_file_txt
  @main_file_txt ||= File.join(prox_folder,'full_text.txt')
end #/ main_file_txt

# Chemin d'acc√®s au fichier qui contient seulement les mots du texte,
# dans l'ordre, pour lemmatisation
def only_mots_path
  @only_mots_path ||= File.join(prox_folder, 'only_mots.txt')
end #/ only_mots_path

def config_path
  @config_path ||= File.join(prox_folder,'config.json')
end #/ config_path
def config_default_data
  {
    last_first_index: 0,
    distance_minimale_commune: 1000,
    last_opening: Time.now.to_i
  }
end #/ config_default_data

def db_path
  @db_path ||= File.join(prox_folder, 'db.sqlite')
end #/ db_path

def data_path
  @data_path ||= File.join(prox_folder,"#{affixe}-prox.data.msh")
end #/ data_path

def corrected_text_path
  @corrected_text_path ||= File.join(prox_folder,"#{affixe}_c#{extension}".freeze)
end #/ corrected_text_path

def prox_folder
  @prox_folder ||= begin
    File.join(folder,"#{affixe}_prox").tap { |pth| `mkdir -p "#{pth}"` }
  end
end #/ prox_folder

def folder
  @folder ||= File.dirname(path)
end #/ folder
def affixe
  @affixe ||= File.basename(path, extension)
end #/ affixe
def extension
  @extension ||= File.extname(path)
end #/ extension


end #/Texte
