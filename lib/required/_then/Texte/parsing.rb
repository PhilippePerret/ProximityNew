# encoding: UTF-8
=begin
  M√©thode de parsing du texte
=end

# Tous les signes, dans le texte, qui vont √™tre consid√©r√©s comme ne
# constituant pas un mot. Donc les apostrophes et les tirets sont exclus.
WORD_DELIMITERS = ' ¬†?!,;:\.‚Ä¶‚Äî‚Äì=+$¬•‚Ç¨¬´¬ª\[\]\(\)<>‚Äú‚Äù' # pas de trait d'union, pas d'apostrophe

# Utile pour la nouvelle formule
REG_NO_WORD_DELIMITERS = /([#{WORD_DELIMITERS}]+)/ # les parenth√®ses vont capturer, dans split.
REG_WORD_DELIMITERS =  /[^#{WORD_DELIMITERS}]+/
REG_APO_OR_TIRET = /[#{APO}#{TIRET}]/.freeze

REG_APO_OR_TIRET_CAP = /([#{APO}#{TIRET}])/.freeze

# Table qui va contenir en cl√© les mots trouv√©s dans le texte et en valeur
# leur canon. Cette table permet de n'enregistrer qu'un seul mot dans la
# table sqlite `lemmas` qui permet de retrouver tr√®s vite un canon de mot.
PARSED_LEMMAS = {}

# Pour les erreurs √† enregistrer
ParsingError = Struct.new(:message, :where)

class Texte
# ---------------------------------------------------------------------
#
#   INSTANCE
#
# ---------------------------------------------------------------------

# Pour ajouter une erreur au cours du parsing
# @usage
#   add_parsing_error(ParsingError.new(<message>))
#
def add_parsing_error(error)
  error = ParsingError.new(error) if error.is_a?(String)
  Errorer << error.message
  log("ERREUR PARSING: #{error.message}")
  @parsing_errors << error
end #/ add_parsing_error

# = main =
# M√©thode g√©n√©rale de parsing, pour n'importe quel document, Scrivener ou
# pas.
def parse

  # Initialisations
  # Il faut tout remettre √† z√©ro, notamment les mots et les Canons.
  self.init
  Canon.init
  Mot.init
  PARSED_LEMMAS.clear
  db.reset

  # Parser en fonction du type du document (simple texte ou projet
  # Scrivener)
  if projet_scrivener?
    projscriv = Scrivener::Projet.new(path, self)
    parse_projet_scrivener(projscriv) || return
  else
    parse_simple_texte || return
  end

  return true # en cas de succ√®s du parsing
end #/ parse



# = main =
#
# M√©thode principale qui traite le fichier
#
# Traiter le fichier consiste √† en faire une entit√© proximit√©, c'est-√†-dire
# un d√©coupage du texte en paragraphes, lines, mots, locutions, non-mots,
# pour permettre le traitement par l'application.
# Le traitement se fait par stream donc le fichier peut avoir une taille
# cons√©quente sans probl√®me
def parse_simple_texte

  # Pour savoir le temps que √ßa prend
  start = Time.now.to_f
  log("*** Parsing du texte #{path}")

  # Pr√©paration du texte
  # --------------------
  # La pr√©paration consiste √† effectuer quelques corrections comme les
  # apostrophes courbes.
  # Le texte corrig√© est mis dans un fichier portant le m√™me nom que le
  # fichier original avec la marque 'c' est il sera normalement d√©truit √†
  # la fin du processus.
  prepare || begin
    log("# Interruption du parsing au niveau de pr√©paration‚Ä¶".freeze, true)
    log.close
    return false
  end

  # On lemmatise la liste de tous les mots, on ajoutant chaque
  # mot √† son canon.
  lemmatize || begin
    log("# Interruption du parsing au niveau de la lemmatisation‚Ä¶".freeze, true)
    log.close
    return false
  end

  save_titems_in_db || begin
    log("# Interruption du parsing au niveau du sauvetage des mots dans la DB‚Ä¶".freeze, true)
    log.close
    return false
  end

  # On doit recalculer tout le texte. C'est-√†-dire d√©finir les
  # offsets de tous les √©l√©ments
  recompte || begin
    log("# Interruption du parsing au niveau du recomptage‚Ä¶".freeze, true)
    log.close
    return false
  end

  # On termine en enregistrant la donn√©e finale. Cette donn√©e, ce
  # sont tous les mots, les canons, ainsi que les pr√©f√©rences sur
  # le texte.
  save

  delai = Time.now.to_f - start

  fin_parsing(path, delai)

  return true

rescue Exception => e
  log("PROBL√àME EN PARSANT le texte #{path} : #{e.message}#{RC}#{e.backtrace.join(RC)}")
  CWindow.error("Une erreur est survenue : #{e.message} (quitter et consulter le journal)")
  return false
ensure
  File.delete(corrected_text_path) if File.exists?(corrected_text_path)
end

# On cr√©e toutes les instances mots dans la base de donn√©es ici
def save_titems_in_db
  self.items.each do |titem|
    titem.insert_in_db
  end
  return true
end #/ save_titems_in_db
# = main =
#
# Parsing d'un projet scrivener.
# Ce parsing est diff√©rent dans le sens o√π plusieurs fichiers texte vont
# permettre de constituer le Runner.itexte final.
def parse_projet_scrivener(projet)

  # Pour savoir le temps que √ßa prend
  start = Time.now.to_f
  log("*** Parsing du projet scrivener #{projet.path}")
  CWindow.log("Parsing du projet scrivener #{projet.name}. Merci de patienter‚Ä¶")

  # Pr√©pare le projet Scrivener et, notamment, la base de donn√©es
  # o√π seront consign√©es les informations sur les fichiers.
  prepare_as_projet_scrivener

  # Effacement des fichiers de parsing.
  erase_parsing_files

  log("Nombre de fichiers √† traiter : #{projet.files.count}")
  projet.files.each do |scrivfile| # instance ScrivFile

    log("** Traitement du fichier scrivener #{scrivfile.uuid}", true)

    # Effacement des fichiers qui se trouvent peut-√™tre dans le
    # dossier du fichier Scrivener courant √† traiter.
    erase_parsing_files(scrivfile)

    # Pr√©paration du
    # --------------------
    # La pr√©paration consiste √† effectuer quelques corrections comme les
    # apostrophes courbes.
    # Le texte corrig√© est mis dans un fichier portant le m√™me nom que le
    # fichier original avec la marque 'c' est il sera normalement d√©truit √†
    # la fin du processus.
    prepare(scrivfile) || begin
      log("# Interruption du parsing au niveau de la pr√©paration de #{scrivfile.name}‚Ä¶".freeze, true)
      log.close
      return false
    end

    # Pour bien s√©parer les fichiers, on ajoute deux retours charriot
    # entre chaque fichier
    @items << NonMot.new(RC, type:'paragraphe')
    @items << NonMot.new(RC, type:'paragraphe')

  end #/ fin de boucle sur chaque fichier du projet Scrivener

  # On lemmatise la liste de tous les mots, on ajoutant chaque
  # mot √† son canon.
  lemmatize || begin
    log("# Interruption du parsing au niveau de la lemmatisation‚Ä¶".freeze, true)
    return false
  end

  save_titems_in_db || begin
    log("# Interruption du parsing au niveau du sauvetage des mots dans la DB‚Ä¶".freeze, true)
    log.close
    return false
  end

  # On doit recalculer tout le texte. C'est-√†-dire d√©finir les
  # offsets de tous les √©l√©ments
  recompte || begin
    log("# Interruption du parsing au niveau du comptage‚Ä¶".freeze, true)
    return false
  end

  # On termine en enregistrant la donn√©e finale. Cette donn√©e, ce
  # sont tous les mots, les canons, ainsi que les pr√©f√©rences sur
  # le texte.
  save

  delai = Time.now.to_f - start

  fin_parsing("PROJET SCRIVENER #{File.basename(projet.path)}", delai)

  return true

rescue Exception => e
  log("PROBL√àME EN PARSANT le projet scrivener #{projet.path} : #{e.message}#{RC}#{e.backtrace.join(RC)}")
  log.close
  erreur("Une erreur est survenue : #{e.message} (quitter et consulter le journal)")
  return false
end #/ parse_projet_scrivener

def init
  @items = []
  @parsing_errors = []
  @refonlymots = nil
  self.current_first_item = 0
  erase_parsing_files
  CWindow.textWind.clear
end #/ init

def show_parsing_errors
  msg = "Des erreurs sont survenues (#{@parsing_errors.count})"
  @parsing_errors.each do |err|
    msg << "#{RC}#{err.message}"
  end
  msg << "#{RC*2}Ces probl√®mes doivent √™tre r√©gl√©s pour pouvoir d√©proximiser ce texte."
  CWindow.textWind.write(msg.freeze)
end #/ show_parsing_errors

def fin_parsing(what, duration)
  unless @parsing_errors.empty?
    show_parsing_errors
  else
    log("üëç¬†PARSING DU #{what} OP√âR√â AVEC SUCC√àS".freeze)
    log("   (dur√©e de l'op√©ration : #{duration})#{RC*2}".freeze)
  end

end #/ fin_parsing

# Eraser les fichiers
# -------------------
# Deux utilisations diff√©rentes de cette m√©thode :
#   * pour un texte quelconque (1 fois au d√©but)
#   * pour un projet Scrivener (pour chaque fichier, 2 fois)
#
# La m√©thode s'appelle √† deux endroits diff√©rents quand on traite un
# projet Scrivener : au commencement du parsing, pour d√©truire les fichiers
# g√©n√©raux et avant le traitement de chaque fichier pour d√©truire les
# full_text_path et les refaire.
# == Params:
#   +scrivfile+   {ScrivFile}   Instance du fichier de Scrivener
#
def erase_parsing_files(scrivfile = nil)
  proprio = scrivfile || self
  file_list = []
  if scrivfile.nil?
    file_list << only_mots_path
    file_list << data_path
    file_list << full_text_path
    file_list << corrected_text_path
    file_list << rebuild_file_path
    file_list << operations_file_path
  else
    file_list << proprio.full_text_path
  end
  file_list.each do |fpath|
    File.delete(fpath) if File.exists?(fpath)
  end
end #/ erase_parsing_files

# Il faut voir s'il est n√©cessaire de parser le fichier. C'est n√©cessaire
# si le fichier d'analyse n'existe pas ou s'il est plus vieux que le
# nouveau texte.
def parse_if_necessary(projetscriv = nil)
  if out_of_date? # Le fichier doit √™tre actualis√©
    log("= Le fichier doit √™tre actualis√©")
    return parse
  else # quand le fichier est √† jour
    return load
  end
end #/ parse_if_necessary


def prepare(sfile = nil)
  if projet_scrivener?
    file_to_correct = sfile.full_text_path
    file_corrected  = sfile.corrected_text_path
    # Il faut pr√©parer le fichier Scrivener
    sfile.prepare
  else # simple copie du fichier texte, si pas projet Scrivener
    FileUtils.copy(path, full_text_path)
    file_to_correct = full_text_path
    file_corrected  = corrected_text_path
  end

  # Pr√©paration d'un fichier corrig√©, √† partir du fichier full-texte
  prepare_fichier_corriged(file_to_correct, file_corrected) || return

  # D√©coupage du fichier corrig√© en mots et non-mots
  decoupe_fichier_corriged(sfile) || return

  return true
end #/ prepare

# On d√©coupe le fichier corrig√© en mot et non mots
# +file_corrected+ est le chemin d'acc√®s au fichier mots corrig√©, pour
# un texte normal, et un des fichiers du projet.
def decoupe_fichier_corriged(scrivfile = nil)
  proprio = scrivfile || self
  file_corrected = proprio.corrected_text_path
  @refonlymots = File.open(only_mots_path,'a') # a √©t√© d√©truit avant
  # On le fait par paragraphe pour ne pas avoir trop √† traiter d'un coup
  File.foreach(file_corrected) do |line|
    next if line.strip.empty?
    new_items = traite_line_of_texte(line.strip)
    next if new_items.empty?
    new_items.each { |titem| titem.file_id = scrivfile.id } unless scrivfile.nil?
    @items += new_items
    # √Ä la fin de chaque ‚Äúligne‚Äù, il faut mettre une fin de paragraphe
    @items << NonMot.new(RC, type: 'paragraphe', file_id: scrivfile&.id)
  end
  # On retire toujours les derniers retours charriot
  @items.pop while @items.last.content == RC
  return true
rescue Exception => e
  erreur(e)
  return false
ensure
  @refonlymots.close
  @refonlymots = nil
end #/ decoupe_fichier_corriged

# Pour √©crire dans le fichier qui ne contient que les mots, s√©par√©s par
# des espaces (pour lemmatisation)
def write_in_only_mots(str)
  @refonlymots.write(str)
end #/ write_in_only_mots

# +refmotscontainer+ R√©f√©rence au fichier contenant tous les mots,
# dans le mode normal et un fichier virtuel pour les insertions et
# remplacement.
# @Params
#   @params   {Hash}
#       :debug    Si true, on affiche les messages de d√©bug
def traite_line_of_texte(line, reffileonlymots = nil, params = nil)
  params ||= {}
  @refonlymots = reffileonlymots unless reffileonlymots.nil?
  new_items = []
  line = line.strip

  # *** Nouvelle fa√ßon de d√©couper le texte ***
  # On utilise la facult√© de String#split √† conserver les d√©limiteurs s'ils
  # sont plac√©s entre parenth√®ses capturantes.
  mots = line.split(REG_NO_WORD_DELIMITERS)
  # Si la liste commence par un string vide, c'est que la ligne commence
  # par un non-mot. Par exemple pour un dialogue, on trouve :
  # [ "", "‚Äî¬†", "Bonjour", " ", "tout", " ", "le", " ", "monde", "¬†!" ]
  line_starts_with_non_mot = mots.first == EMPTY_STRING

  log("Les mots d√©coup√©s : #{mots.inspect}") if params[:debug]

  # On retourne les listes pour pouvoir pop(er) au lieu de shift(er) pour
  # des raisons de performances. Mais pour des listes aussi courtes, est-ce
  # qu'on ne perd pas plus de temps √† reverser qu'√† shift(er) au lieu de
  # pop(er) ?‚Ä¶
  # Rappel : #pop va plus vide que #shift car la seconde est oblig√©e de
  # r√©-indexer toute la liste √† chaque fois.
  mots.reverse!

  # Si la ligne ne commence pas par un mot, il faut prendre ce non-mot et
  # le mettre au d√©but de la liste des nouveaux text-items.
  if line_starts_with_non_mot
    mots.pop # pour retirer le string vide d√©coulant de la d√©coupe
    new_items << NonMot.new(mots.pop)
  end

  # On traite ensuite le mot et son non-mot suivant.
  begin
    mot     = mots.pop
    nonmot  = mots.pop # peut √™tre nil
    imot = TextWordScanned.new(mot, nonmot)
    new_items += imot.scan

    imot = nil
  end until mots.empty?

  # Maintenant qu'on a tous les text-items de la phrase, on peut
  # ajouter les mots dans le fichier des mots seulement. On en profite
  # pour d√©finir la propri√©t√© :lemma qui est peut-√™tre d√©j√† d√©finie (voir
  # l'explication dans la classe Mot)
  new_items.each do |titem|
    if titem.content.nil?
      raise "TITEM NIL #{titem.inspect} items:#{new_items.inspect} (line: #{line})"
    end
    next unless titem.mot?
    titem.lemma ||= titem.content.downcase
    write_in_only_mots("#{titem.lemma}#{titem.is_colled ? EMPTY_STRING : SPACE}".freeze)
  end

  return new_items
end #/ traite_line_of_texte

# On prend le fichier texte (contenant tout le texte initial ou le texte
# du fichier d'un projet Scrivener) et on le corrige pour qu'il puisse √™tre
# trait√©. Cette op√©ration @produit le fichier +file_corrected_path+
def prepare_fichier_corriged(file_to_correct, file_corrected_path)
  log("*** Pr√©paration du fichier corrig√©")
  File.delete(file_corrected_path) if File.exists?(file_corrected_path)
  reffile = File.open(file_corrected_path,'a')
  begin
    has_apostrophes_courbes = nil
    File.foreach(file_to_correct) do |line|
      next if line == RC # on passe les retours charriot seuls
      if !has_apostrophes_courbes
        has_apostrophes_courbes = !!line.match?(/‚Äô/)
        # log("has_apostrophes_courbes = #{has_apostrophes_courbes.inspect}")
      end
      line = line.gsub(/‚Äô/, APO)
      reffile.puts line
    end
    # Il faut enregistrer dans les informations du texte que les
    # apostrophes courbes ont √©t√© remplac√©es, ou pas
    config.save(apostrophes_courbes: has_apostrophes_courbes)
    # log("Configuration enregistr√©e (apostrophes_courbes: #{has_apostrophes_courbes.inspect})")
    return true
  rescue Exception => e
    erreur(e)
    return false
  ensure
    reffile.close
  end
end #/ prepare_fichier_corriged

# Quand on doit pr√©parer le texte comme un projet scrivener
def prepare_as_projet_scrivener
  log("-> prepare_as_projet_scrivener".freeze)
  ScrivFile.create_table_base_for(Runner.itexte) || return
  return true
rescue Exception => e
  erreur(e)
  return false
end #/ prepare_as_projet_scrivener

# L√©mmatiser le texte consiste √† le passer par tree-tagger ‚Äî ce qui prend
# quelques secondes m√™me pour un grand texte¬†‚Äî pour ensuite r√©cup√©rer chaque
# mot et connaitre son canon dans le texte final
#
# Pour savoir de quel mot il s'agit, on se sert de l'index dans Mot.items
# et de l'index dans le fichier only_mots_path. Cet index correspond.
def lemmatize
  log("*** Lemmatisation du fichier", true)
  Lemma.parse(self)
  # log("Contenu du fichier lemma_data_path : #{File.read(lemma_data_path)}")
  File.foreach(lemma_data_path).with_index do |line, mot_idx_in_lemma|
    next if line.strip.empty?
    traite_lemma_line(line, mot_idx_in_lemma) || return
  end # Fin de boucle sur chaque ligne du fichier de lemmatisation
  return true
end #/ lemmatize

# Traite une ligne de type mot TAB type TAB canon r√©cup√©rer
# des donn√©es de lemmatisation, soit au cours du parse complet du fichier
# √† travailler, soit aucun d'une insertion/remplacement
def traite_lemma_line(line, idx)
  mot, type, canon = line.strip.split(TAB)
  # Traitement de quelques cas <unknown> connus‚Ä¶ (sic)
  if canon == LEMMA_UNKNOWN
    log("+++ canon inconnu pour : #{line}")
    type, canon = case mot
    when 't' then ['PRO:PER', 'te']
    else [type, canon]
    end
  end
  titem = Mot.items[idx]
  titem.type = type
  if mot != (titem.lemma || titem.content.downcase)
    expose_erreur_desynchro(mot:mot, titem:titem, idx:idx, canon:canon)
  else
    # Quand le mot lemmatis√© correspond au mot enregistr√© dans Mot.items (cas
    # normal)
    # on peut d√©finir le canon du mot. (sera supprim√© dans les version ult√©rieures)
    Canon.add(Mot.items[idx], canon)
    # On regarde s'il faut enregistrer cette forme lemmatis√©e
    # On le sait de deux mani√®res : en consultant la table des mots qui ont
    # d√©j√† √©t√© lemmatis√©s au cours de ce parsing (pour aller plus vite) et en
    # regardant si ce canon est connu dans la table `lemmas` de l'application.
    # Si c'est le cas, on renseigne la table `lemmas` de la base de donn√©es de
    # proximit√© (Runner.db) pour que cette forme soit accessible √† tout
    unless PARSED_LEMMAS.key?(mot) || Runner.db.canon_exists_for?(mot)
      PARSED_LEMMAS.merge!(mot => canon)
      Runner.db.add_mot_and_canon(mot, type, canon)
    end
  end
  return true
end #/ traite_lemma_line

# Quand une erreur de desynchro (*) se pose, on donne le maximum de
# renseignements pour pouvoir corriger le probl√®me.
#
# (*) Une erreur de d√©synchro signifie que le fichier pour la lemmatisation
#     ne correspond plus √† la liste des mots enregistr√©e dans Mot.items qui
#     a √©t√© compos√©e au moment du parsing du texte.
#
def expose_erreur_desynchro(params)
  # erreur(err)

  # Donn√©es envoy√©es par +params+
  idx = params[:idx]
  mot = params[:mot]
  titem = params[:titem]
  canon = params[:canon]

  # Informations sur le mot lemma et le text-item
  log("### Informations sur le mot et le text-item :")
  log("### Index : #{idx}")
  log("### Text-item")
  log("###    content  : #{titem.content.inspect}")
  log("###    type     : #{titem.type.inspect}")
  log("###    lemma    : #{titem.lemma.inspect}")
  log("###    file_id : #{titem.file_id} / Path: #{ScrivFile.get_path_by_file_id(titem.file_id)}") if titem.file_id
  log("### Mot lemmatis√© (fichier des seuls mots)")
  log("###    mot    : #{mot.inspect}")
  log("###    canon  : #{canon.inspect}")

  if mot.match?(REG_APO_OR_TIRET)
    # Si le mot contient une apostrophe ou un tiret, on sugg√®re de l'ajouter √†
    # la liste des mot sp√©ciaux de chaque type.
    liste_prog, liste_perso, chose = mot.match?(/'/) ? ['MOTS_APOSTROPHE', 'avec apostrophe', 'mot_apostrophe'] : ['MOTS_TIRET', 'avec tirets', 'mot_tiret']
    msg = "### Mots ne correspondant pas."
    msg << "### Le mot #{mot.inspect} (index #{idx}) peut √™tre √† ajouter √† la liste des mots sp√©ciaux #{liste_perso}#{RC}"
    msg << "### avec la commande :add #{chose} #{mot}#{RC}"
    msg << "### Si c'est un mot commun, l'ajouter √† #{liste_prog} dans lib/required/_first/contants/proximites.rb"
  else
    # Le mot ne contient ni tiret ni apostropthe, c'est un mot normal,
    # on affiche l'extrait du texte pour voir ce que √ßa peut √™tre.
    # Extrait √† partir des mots
    extrait = ("‚Ä¶" + ((idx - 20)..(idx + 20)).collect do |i|
      i > -1 || next
      Mot.items[i]&.content
    end.compact.join(SPACE) + '‚Ä¶').freeze
    # Extrait √† partir des lignes
    extrait_lemma = []
    File.foreach(lemma_data_path).with_index do |line, sidx|
      next if sidx < idx - 20
      break if sidx > idx + 20
      extrait_lemma << line.split(TAB).first
    end
    extrait_lemma = extrait_lemma.join(SPACE)

    # Extrait autour du mot probl√©matique
    extraitautour = {}
    File.foreach(lemma_data_path).with_index do |line, sidx|
      # next if sidx < idx - 20
      break if sidx > idx + 10
      extraitautour.merge!( sidx => {lemma:line.split(TAB).first, mot:Mot.items[sidx]&.content} )
    end

    extraitautour = extraitautour.collect{|sidx,hd|"idx:#{sidx} - lemma:#{hd[:lemma]} - mot:#{hd[:mot]}"}.join(RC)


    msg = "Probl√®me avec le mot d'index #{idx} #{titem.content.inspect} (dans Mot.items) diff√©rent de #{mot.inspect} (dans le fichier des mots seulement) dans l'extrait :#{RC}#{extrait.inspect}."
    msg << "#{RC}Extrait dans le fichier des mots seuls :#{RC}#{extrait_lemma}"
    if mot == Mot.items[idx+1].content.downcase
      msg << "#{RC}MAIS √ßa correspond √† l'imot suivant d'index #{idx+1}." # on pourrait r√©parer
    end

    msg << "#{RC}Voir dans le fichier journal le d√©tail"
    log(extraitautour)
  end
  msg << RC*2
  add_parsing_error(msg)
  log(msg, true)
  err = "### ERREUR FATALE LES MOTS NE CORRESPONDENT PLUS (index : idx).".freeze
  raise(err)
end #/ expose_erreur_desynchro

end #/Texte
