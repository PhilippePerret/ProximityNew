# encoding: UTF-8
=begin
  M√©thode de parsing du texte
=end
class Texte
# ---------------------------------------------------------------------
#
#   INSTANCE
#
# ---------------------------------------------------------------------

# = main =
#
# M√©thode principale qui traite le fichier
#
# Traiter le fichier consiste √† en faire une entit√© proximit√©, c'est-√†-dire
# un d√©coupage du texte en paragraphes, lines, mots, locutions, non-mots,
# pour permettre le traitement par l'application.
# Le traitement se fait par stream donc le fichier peut avoir une taille
# cons√©quente sans probl√®me
def parse

  # Pour savoir le temps que √ßa prend
  start = Time.now.to_f
  log("*** Parsing du texte #{path}")

  # Initialisations
  self.init
  Canon.init

  # Pr√©paration du texte
  # --------------------
  # Pour un projet Scrivener, √ßa consiste √† reconstituer tout le
  # texte si n√©cessaire.
  # La pr√©paration consiste √†
  #   effectuer quelques corrections comme les apostrophes courbes.
  # Le texte corrig√© est mis dans un fichier portant le m√™me nom que le
  # fichier original mais la marque 'c' est il sera normalement d√©truit √†
  # la fin du processus.
  prepare || return

  # On lemmatise la liste de tous les mots, on ajoutant chaque
  # mot √† son canon.
  lemmatize || return

  # On doit recalculer tout le texte. C'est-√†-dire d√©finir les
  # offsets de tous les √©l√©ments
  recompte || return

  # On termine en enregistrant la donn√©e finale
  save

  delai = Time.now.to_f - start
  puts "D√©lai secondes m√©thode : #{delai}"

  return true
rescue Exception => e
  log("PROBL√àME EN PARSANT le texte #{path} : #{e.message}#{RC}#{e.backtrace.join(RC)}")
  CWindow.error("Une erreur est survenue : #{e.message} (quitter et consulter le journal)")
ensure
  File.delete(corrected_text_path) if File.exists?(corrected_text_path)
end


def init
  @items = []
  self.current_first_item = 0
  erase_parsing_files
end #/ init

def erase_parsing_files
  [data_path, main_file_txt, only_mots_path].each do |fpath|
    File.delete(fpath) if File.exists?(fpath)
  end
end #/ erase_parsing_files

# Il faut voir s'il est n√©cessaire de parser le fichier. C'est n√©cessaire
# si le fichier d'analyse n'existe pas ou s'il est plus vieux que le
# nouveau texte.
def parse_if_necessary
  if out_of_date?
    # log "Le fichier doit √™tre actualis√©"
    parse || return
    log("üëç¬†PARSING OP√âR√â AVEC SUCC√àS".freeze)
  else
    # log "Le fichier est √† jour"
    load
  end
  return true
end #/ parse_if_necessary


def prepare
  # Pr√©paration d'un fichier "full-texte" contenant tout le texte √† corriger
  if projet_scrivener?
    prepare_as_projet_scrivener || return
  else # simple copie si pas projet Scrivener
    FileUtils.copy(path, main_file_txt)
  end

  # Pr√©paration d'un fichier corrig√©, √† partir du fichier full-texte
  prepare_fichier_corriged || return

  # D√©coupage du fichier corrig√© en mots et non-mots
  decoupe_fichier_corriged || return

  return true
end #/ prepare

# Tous les signes, dans le texte, qui vont √™tre consid√©r√©s comme ne
# constituant pas un mot. Donc les apostrophes et les tirets sont exclus.
DELIMITERS = ' ¬†?!,;:\.‚Ä¶‚Äî‚Äì=+$¬•‚Ç¨¬´¬ª' # pas de trait d'union, pas d'apostrophe

MOT_NONMOT_REG = /([#{DELIMITERS}]+)?([^#{DELIMITERS}]+)([#{DELIMITERS}]+)/

# On d√©coupe le fichier corrig√© en mot et non mots
def decoupe_fichier_corriged
  # On pr√©pare le fichier pour la l√©mmatisation. Il ne contiendra que
  # les mots, s√©par√©s par des espaces simple
  File.delete(only_mots_path) if File.exists?(only_mots_path)
  refonlymots = File.open(only_mots_path,'a')
  # On le fait par paragraphe pour ne pas avoir trop √† traiter d'un coup
  File.foreach(corrected_text_path) do |line|
    # log("Phrase originale: #{line.inspect}")
    new_items = traite_line_of_texte(line.strip, refonlymots)
    log("#{new_items.count} ajout√©s √† itexte.items")
    @items += new_items
    # √Ä la fin de chaque ‚Äúligne‚Äù, il faut mettre une fin de paragraphe
    @items << NonMot.new(RC, type: 'paragraphe')
  end
  # On retire toujours les derniers retours charriot
  @items.pop while @items.last.content == RC
  return true
rescue Exception => e
  erreur(e)
  return false
ensure
  refonlymots.close
end #/ decoupe_fichier_corriged

# +refmotscontainer+ R√©f√©rence au fichier contenant tous les mots,
# dans le mode normal et un fichier virtuel pour les insertions et
# remplacement.
def traite_line_of_texte(line, refmotscontainer)
  new_items = []
  line.scan(MOT_NONMOT_REG).to_a.each_with_index do |item, idx|
    # next if item.nil? # pas de premier d√©limiteur par exemple
    amorce, mot, nonmot = item # amorce : le tiret, par exemple, pour dialogue
    new_items << NonMot.new(amorce) unless amorce.nil?
    if mot.match?(/#{APO}/) && !MOTS_APOSTROPHE.key?(mot.downcase)
      # log("MOT APOSTROPHE √Ä D√âCOUPER : #{mot.inspect}")
      bouts = mot.split(APO)
      motav = bouts.shift
      motap = bouts.join(APO)
      motav += APO
      new_items << Mot.new(motav)
      new_items << Mot.new(motap)
    elsif mot.match?(/#{TIRET}/) && !MOTS_TIRETS.key?(mot.downcase)
      mots = []
      bouts = mot.split(TIRET)
      mots << bouts.shift
      motap = bouts.join(TIRET)
      if motap.match?(/#{TIRET}/) && !MOTS_TIRETS.key?(motap.downcase)
        mots += motap.split(TIRET)
        mots.last = "#{TIRET}#{mots.last}" # on garde "-il"
      else
        mots << "#{TIRET}#{motap}" # on garde "-il"
      end
      mots.each do |smot|
        new_items << Mot.new(smot)
      end
    else
      new_items << Mot.new(mot)
    end
    # Dans tous les cas, m√™me avec une apostrophe, on √©crit le mot tel
    # qu'il est. Parce que lors de la l√©mmatisation, avec l'apostrophe, il
    # y aura deux mots trouv√©s alors que "D' aussi" produira "D" (inconnu)
    # et "aussi"
    # On le met en minuscule, car sinon, la l√©mmatisation ne comprend pas
    # un mot avec capitale au milieu d'une phrase
    refmotscontainer.write("#{mot.downcase}#{SPACE}".freeze)
    new_items << NonMot.new(nonmot)
  end #/scan
  return new_items
end #/ traite_line_of_texte

# On prend le fichier total (contenant tout le texte initial) et on
# le corriger pour qu'il puisse √™tre trait√©
# Cette op√©ration @produit le fichier self.corrected_text_path
def prepare_fichier_corriged
  File.delete(corrected_text_path) if File.exists?(corrected_text_path)
  reffile = File.open(corrected_text_path,'a')
  begin
    File.foreach(main_file_txt) do |line|
      next if line == RC
      line = line.gsub(/‚Äô/, APO)
      reffile.puts line + PARAGRAPHE
    end
    return true
  rescue Exception => e
    erreur(e)
    return false
  ensure
    reffile.close
  end
end #/ prepare_fichier_corriged

# Quand on doit pr√©parer le texte comme un projet scrivener
def prepare_as_projet_scrivener
  log("-> prepare_as_projet_scrivener".freeze)
  ScrivFile.create_table_base_for(Runner.itexte) || return
  projet = Scrivener::Projet.new(path)
  # Pr√©parer le fichier contenant tout le texte si n√©cessaire
  unless File.exists?(main_file_txt)
    projet.produit_fichier_full_text || return
  end
  return true
rescue Exception => e
  erreur(e)
  return false
end #/ prepare_as_projet_scrivener

# L√©mmatiser le texte consiste √† le passer par tree-tagger ‚Äî ce qui prend
# quelques secondes m√™me pour un grand texte¬†‚Äî pour ensuite r√©cup√©rer chaque
# mot et connaitre son canon dans le texte final
def lemmatize
  @lemmatized_file_path = Lemma.parse(only_mots_path)
  # log("Contenu du fichier lemmatized_file_path : #{File.read(lemmatized_file_path)}")
  File.foreach(lemmatized_file_path).with_index do |line, mot_idx_in_lemma|
    next if line.strip.empty?
    traite_lemma_line(line, mot_idx_in_lemma) || break
  end # Fin de boucle sur chaque ligne du fichier de lemmatisation
  return true
end #/ lemmatize

# Traite une ligne de type mot TAB type TAB canon r√©cup√©rer
# des donn√©es de lemmatisation, soit au cours du parse complet du fichier
# √† travailler, soit aucun d'une insertion/remplacement
def traite_lemma_line(line, idx)
  mot, type, canon = line.strip.split(TAB)
  Mot.items[idx].type = type
  if mot != Mot.items[idx].content.downcase
    erreur("ERREUR FATALE LES MOTS NE CORRESPONDENT PLUS¬†:")
    imot = Mot.items[idx]
    log("mot:#{mot.inspect}, dans imot: #{imot.content.inspect}, type:#{type.inspect}, canon: #{canon.inspect}")
    return false
  else # quand tout est normal
    Canon.add(Mot.items[idx], canon)
  end
  return true
end #/ traite_lemma_line

end #/Texte
